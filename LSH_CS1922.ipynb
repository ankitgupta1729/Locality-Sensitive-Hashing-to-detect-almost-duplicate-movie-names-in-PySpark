{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "LSH_CS1922.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aP55FYcclpmv"
      },
      "source": [
        "# Locality Sensitive Hashing\n",
        "\n",
        "In this assignment you will implement localitiy sensitive hashing step-by-step and apply that on detecting almost duplicate names. You are required to implement the functions as instructed. Do not change the signatures of the functions.\n",
        "\n",
        "## Submission instruction\n",
        "\n",
        "Submit a text file with extension .py containing the functions you have implemented. You can simply use the \"download as\" option from Jupyter notebook to export the notebook as a .py file. The filename should be LSH_{YOUR_ROLL_NO}.py where {YOUR_ROLL_NO} is your 6 letter roll number. For example, a sample file name would be LSH_CS1702.py. Please take this seriously and name the file correctly. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJV-82mPsX1j"
      },
      "source": [
        "## Important: do not change the function signatures\n",
        "\n",
        "You need to implement the functions given in this notebook. You may define more functions at your will if you need to, but make sure you implement the functions given and do not change their signatures. Before submitting, remove unnecessary print / collect statements in order to avoid too much console output. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80rNtM8MpgVr"
      },
      "source": [
        "## Setup environment\n",
        "\n",
        "We need to setup pyspark and pydrive. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Hd949j7lqrP",
        "outputId": "c8f2e480-ccb4-468b-ca5b-50f2ad14587f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.6/dist-packages (3.0.1)\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.6/dist-packages (from pyspark) (0.10.9)\n",
            "openjdk-8-jdk-headless is already the newest version (8u272-b10-0ubuntu1~18.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 11 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdopBj2EppQW"
      },
      "source": [
        "Follow the interactive instructions for accessing the file in Google drive. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwKLoRXtpBnG"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvuiD4jerQxL"
      },
      "source": [
        "### Load the appropriate file\n",
        "\n",
        "The files are shared on Google drive, with the following ids given. Choose to keep the appropriate line, use the corresponding filename and comment the others. After executing, you should be able to see the file in the files section on the left panel. \n",
        "\n",
        "<b>You may face troubles trying to run your code on the full data, so it is totally okay to run it on one of the smaller files.</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIISWg9IpXpy"
      },
      "source": [
        "#id='1aoZykfz5GLGGw3lRA86ogd7yCsgkgHoT' # for titles-small.txt\n",
        "id='1IPssUa3m-zfWmvVbLtI-lKhJbeZjIgBg' # for titles-10k.txt (with 10k titles, mid sized file) #taking this dataset for this assignment\n",
        "# id='1RzTA4iOfH3bOiyG2kDaxweUuj4AEcMda' # \n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('titles-10k.txt')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ip5HQz_lKFA"
      },
      "source": [
        "## Parameters\n",
        "\n",
        "Let us set our parameters. You are free to change these around and experiment. However, do not hardcode them anywhere else in the code. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNyxM7EClKFE"
      },
      "source": [
        "#The following tunable parameters are considered for the assignment \n",
        "# Number of hash functions\n",
        "n = 20\n",
        "# size of each shingle\n",
        "k = 3\n",
        "# Number of bands \n",
        "b = 4"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PV5J2SuLDVnq"
      },
      "source": [
        "$\\textbf{Note:}$ Please open the notebook in Google colab otherwise it might show indentation error in local sytem because here 2 whitespace works for indentation but in local system, jupyter notebook takes 4 whitespaces or tab for indentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFb4-dZZlKFV"
      },
      "source": [
        "### 1. Converting a string to shingles (of characters) [Marks: 5] \n",
        "\n",
        "In our setup, the items we would compare are movie titles (strings). You would have to convert names to sets of k-shingles (of characters), <i>after removing the whitespaces</i> and <i>converting to lowercase</i>. For example, the 3-shingling of the name <tt>'Die hard'</tt> would be <tt>['die', 'ieh', 'eha', 'har', 'ard']</tt>.\n",
        "\n",
        "Implement the following function which takes a string and k as input and outputs the list of unique shingles generated from the string. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK1eeBHllKFX"
      },
      "source": [
        "def string_to_shingles(name, k):\n",
        "  shingles=[]\n",
        "  name=name.lower() # it converts given string to all lower characters strings \n",
        "  string=\"\".join(name.split()) # it removes the whitepaces from the string after converting all characters to lower case characters\n",
        "  #print(str)\n",
        "  for s in range(len(string)-k+1):\n",
        "    shingles.append(string[s:s+k]) # taking k-length shingles\n",
        "  return list(set(shingles)) # to get unique shingles, first convert list to set to remove duplicates and at the end, \n",
        "  # returns list of unique shingles generated from the string"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7dMLD9IlKFh"
      },
      "source": [
        "Also test your code. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW7ApXfalKFi"
      },
      "source": [
        "#print(string_to_shingles('Die hard',3))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fN53xbKWlKFp"
      },
      "source": [
        "### 2. Generating the shingle - item matrix from the whole data [Marks: 20]\n",
        "\n",
        "For each title, first give it an ID. You can do it by the <tt>zipWithIndex()</tt> operation on Spark RDDs. Try testing it first. \n",
        "\n",
        "Then, for each title, get the list of shingles in map and for each unique shingle, get the list of IDs using reduce. \n",
        "\n",
        "Tips: when your input RDD is a list of tuples of the following form:\n",
        "\n",
        "<tt>\n",
        "    [('Die hard', 0),\n",
        " ('Die another day', 1),\n",
        " ('Tomorrow never dies', 2),\n",
        " ('Chup ke chup ke', 3), .... ]\n",
        "</tt>\n",
        "\n",
        "for each tuple <tt>t</tt>, you may use <tt>t[0], t[1]</tt> etc to access the first, second (and so on) elements of the tuples. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUU6Ih_l4Rkr"
      },
      "source": [
        "The \"titles-10k.txt\" file has total 10k movie titles which are loaded in the titles RDD.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgDF2QXhlKFq"
      },
      "source": [
        "from pyspark import SparkContext, SparkConf\n",
        "sc = SparkContext.getOrCreate()\n",
        "\n",
        "# Use appropriate file path here\n",
        "titles = sc.textFile(\"titles-10k.txt\")  \n",
        "\n",
        "# Get the number of titles\n",
        "N = titles.count()  # N=10000 = total number of movie titles\n",
        "itemsByShingles = titles.zipWithIndex() # associate a unique id for each title."
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8ZYEy4c5RuP"
      },
      "source": [
        "Here, we convert each title to a 3-shingles and keyval is a list of key-value pair in which key has title and value is a list of 3-shingles for corresponding title. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BSNRrAn7yil"
      },
      "source": [
        "keyval=titles.map(lambda x: (x,string_to_shingles(x,k)))  \n",
        "#keyval.takeSample(False,5) # taking a sample of size 5 without replacement   "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8kic54G5yNp"
      },
      "source": [
        "Here, keyval1 returns the key-value pair where key is a list of 3-shingles for a particular title and corresponding movie id. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6cDpKy177Lh"
      },
      "source": [
        "keyval1=itemsByShingles.map(lambda x: (string_to_shingles(x[0],k),x[1])) \n",
        "#keyval1.takeSample(False,5)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wgtnlswj6e1Z"
      },
      "source": [
        "From the list of \" ( [list of 3-shingles] , movie-id ) \", I make a pair of a particular shingle and movie id. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfxZ6fTV8CXK"
      },
      "source": [
        "key_val=keyval1.flatMap(lambda n: [(x, n[1]) for x in n[0]]) \n",
        "#key_val.takeSample(False,5)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYARgUJS8JeX"
      },
      "source": [
        "#print(key_val.count())"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTJcL-uL7AHW"
      },
      "source": [
        "Here, result returns a key-value pair where key is a shingle and and value is the list of movie id associated with a particular shingle which is the objective of this part."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOCRBD2nxSnQ"
      },
      "source": [
        "## Answer 1 : Each unique 3-shingle with list of movie IDs<br>\n",
        "After comment out the \"result.takeSample(False,5)\", it will give the desired output for sample size of 5 without replacement "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzkmjM6K8ZL1"
      },
      "source": [
        "result=key_val.combineByKey(lambda v:[v],lambda x,y:x+[y],lambda x,y:x+y) \n",
        "#result.takeSample(False,5)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyT2HkqMReC4"
      },
      "source": [
        " #result.count() # returns total number of unique shingles"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_d0GR-9lKF2"
      },
      "source": [
        "At the end of this step, the <tt>itemsByShingles</tt> RDD should have the list of (shingle, [list of movie ids]).\n",
        "\n",
        "If you display your output, it should look like:\n",
        "\n",
        "[(shingle, [list of movie ids]), (shingle, [list of movie ids]), ... ]\n",
        "\n",
        "<b>However, do not keep collect or large print statements in your code at the time of submitting.</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52zB-SZjlKF3"
      },
      "source": [
        "### 3. Computation of min-hash signature matrix [Marks: 10 + 10 = 20]\n",
        "\n",
        "Instead of using random permutations, you will implement min-hash function using Murmurhash (v3) functions, as discussed in the class. The input to your function should be a <i>title</i> (which corresponds to a row) and the output should be a number (hash value). \n",
        "\n",
        "Recall the outline of the min-hash signature matrix algorithm:<br><br>\n",
        "\n",
        "<tt>\n",
        "1. For each row $r$ BEGIN<br>\n",
        "2. &emsp;Compute $h_1(r), h_2(r),…, h_n(r)$<br>\n",
        "3. &emsp;  For each column $j$ BEGIN <br>\n",
        "4. &emsp; &emsp;  If the $j$-th column has 1 in row $r$ <br>\n",
        "5. &emsp;&emsp;&emsp; For each $i = 1, 2, … , n$ BEGIN <br>\n",
        "6. &emsp;&emsp;&emsp;&emsp; set $\\mathrm{SIG}_{i,j} = \\min(\\mathrm{SIG}_{i,j}, h_i(r))$<br>\n",
        "7. &emsp;&emsp;&emsp;            END <br>\n",
        "8. &emsp;&emsp;        END IF<br>\n",
        "9. &emsp;  END<br>\n",
        "10. END\n",
        "</tt>\n",
        "\n",
        "For each shingle, we have the list of movie IDs which contain the shingle. So, for each shingle (each row), we can perform the actions in lines 5-7 only for the movie IDs that are present in the list. For any other $j$, the $j$-th column does not have a 1 in row $r$. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZ5WkPmllKF4"
      },
      "source": [
        "Do not create a SIG matrix and try to update it. Instead, note that for every 1-entry in the shingle-id matrix (that is, every id in the list corresponding to a shingle), the corresponding (i, id)-th entry of the signature matrix may get potentially updated. Simply output the tuple ((i, id), h_i(text)) in another map. The final value of the (i,id)-th entry of the signature matrix is the minimum of all such h_i(text) values obtained in this process. That minimum can be computed by another reduce process. \n",
        "\n",
        "### (a) The map [Marks: 10 out of 20]\n",
        "To make it easier, you may implement an <tt>update_signature</tt> function which takes the shingle (text), the list of ids associated with the shingle and the total number of shingles (for computing the hash values). It should simply return the tules <tt>((i, id), h_i(text))</tt> for all i = 1, ..., n. \n",
        "\n",
        "<b>Note:</b> There has been a correction here. Instead of N (the number of movie ids), we need to pass the number of Shingles here. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1jvtV_vgRKQ",
        "outputId": "84ce6c66-1a3f-49fe-efb3-08586d1571ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip3 install mmh3 "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mmh3 in /usr/local/lib/python3.6/dist-packages (2.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbavGY1d9ahc"
      },
      "source": [
        "Here, mmh3 returns the key-value pair where key is a tuple of hash-function index and movie id and value is hash-value. Actually, here, key is $(i,j)^{th}$ entry in signature matrix and value is value in that $(i,j)^{th}$ entry for the signature matrix. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZuWAxuRzC0D"
      },
      "source": [
        "## Answer 3(a):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXe__TuOlKF5"
      },
      "source": [
        "import mmh3\n",
        "def update_signature(text, ids, numOfShingles):\n",
        "    \n",
        "    # h = [mmh3.hash(text,i) % (total number of shingles) for i in range(n)]\n",
        "  \n",
        "  min_sig = []\n",
        "  for i in range(n):\n",
        "    for j in range(len(ids)):\n",
        "      temp=[]\n",
        "      temp2=[]\n",
        "      temp.append(i)\n",
        "      temp.append(ids[j])\n",
        "      temp2.append(tuple(temp))\n",
        "      temp2.append(mmh3.hash(text,i) % (numOfShingles))\n",
        "      min_sig.append(tuple(temp2))\n",
        "     \n",
        "    \n",
        "  return min_sig "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGjtSLqPlKF9"
      },
      "source": [
        "### (b) The reduce [Marks: 10 out of 20]\n",
        "\n",
        "Now that you have all <tt>((i, id), h_i(shingle))</tt> tuples output by the map, use reduce to compute the minimum of <tt>h_i(shingle)</tt> for every <tt>(i,id)</tt> key. This would produce the signature matrix in a sparse matrix representation. \n",
        "\n",
        "You may actually implement the map function above and call map and reduce together later as well. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR3hCwmm-TaJ"
      },
      "source": [
        "Here, new_key_val returns the list of key-value pair where where key is a pair of hash-function id $i= 0$ to $(n-1)$ and a movie-id. Value in the key-value pair is value of the hash-function where input is a unique 3-shingle. Here, key-value pairs are corresponding to the unique 3-shingle and associated list of movie-ids."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NCC1IQjlKF9"
      },
      "source": [
        "numOfShingles = result.count() # Calculate, you need to pass this to the update_signature function\n",
        "\n",
        "# You should use map with the update_signature function and a reduce \n",
        "#new_key_val=result.flatMap(lambda n: [(x, n[1]) for x in n[1]])\n",
        "\n",
        "new_key_val=result.map(lambda x: update_signature(x[0],x[1],numOfShingles) )\n",
        "#new_key_val.takeSample(False,2)\n",
        "new_key_val = new_key_val.flatMap(lambda list: list)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YB7s5yCLp_oX"
      },
      "source": [
        "#print(result.count(),new_key_val.count())"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keZuTAIGALha"
      },
      "source": [
        "Now, signature returns the signature matrix which is our objective for this part.It is in the form of $((i,j),k)$ where, $(i,j)$ represents the $(i,j)^{th}$ entry of the signature matrix and $k$ is the value of the hash function.<br>\n",
        "<br>\n",
        "$\\textbf{Note:}$ Here,  size of the signature matrix is $199960$ , not $20 \\times 10000 = 200000$. The reason is, in the original dataset \"titles-10k.txt\", there are $2$ movie titles \"99\" and \"S1\" for which I can't generate 3-shingle. So, size of the signature matrix will be $20*(10000-2)= 199960.$ \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mrsb6fyWyVLu"
      },
      "source": [
        "## Answer 3 (b): Signature Matrix <br>\n",
        "After commnet out the \"signature.takeSample(False,5)\", it will give the desired output.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4CnA9SOur8u"
      },
      "source": [
        "signature = new_key_val.reduceByKey(min)\n",
        "#signature.takeSample(False,5)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwwBw56vxeW-"
      },
      "source": [
        "#signature.count() \n",
        "\n",
        "\n",
        "#Here, size of the signature matrix is 199960 , not 20×10000=200000. The reason is, in the original dataset \"titles-10k.txt\", \n",
        "#there are 2 movie titles \"99\" and \"S1\" for which I can't generate 3-shingle. So, movie IDs are not considered for these titles\n",
        "#So, size of the signature matrix will be 20∗(10000−2)=199960."
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFr1f8DqlKGB"
      },
      "source": [
        "The RDD signature should be of the following form:\n",
        "\n",
        "<tt>\n",
        "    [((0, 1), 5), ((0, 3), 56), ... \n",
        "    ]\n",
        "</tt>\n",
        "\n",
        "where each tuple <tt>((i,j),v)</tt> represents the $(i,j)$-th entry of the signature matrix with value $v$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5InmG56-lKGB"
      },
      "source": [
        "### 4. Implement the banding [Marks: 15]\n",
        "\n",
        "Now configure your number of bands $b$ (a divisor of number of hash functions $n$) and implement the candidate pair computation. Any pair of movies which agree completely in their signature on at least one band should be output as candidate pairs. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgCPrtjcCatm"
      },
      "source": [
        "Here, signature matrix is divided into 4 parts by rows since there are 4 bands and number of rows in each band is 5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kS2K6UbMlKGB"
      },
      "source": [
        "#r=n/b = 20/4 = 5\n",
        "\n",
        "band1=signature.filter(lambda x : x[0][0] >=0 and x[0][0]<=4)\n",
        "band2=signature.filter(lambda x : x[0][0] >=5 and x[0][0]<=9)\n",
        "band3=signature.filter(lambda x : x[0][0] >=10 and x[0][0]<=14)\n",
        "band4=signature.filter(lambda x : x[0][0] >=15 and x[0][0]<=19)\n",
        "\n",
        "candidate_pairs = []"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNU1QQdKC_Uf"
      },
      "source": [
        "Since, I get the candidate pairs in band1 where pair of movies completely agree in their signature, so I will not check the other bands. The logic to find the candidate pair which I have used is: first for a band1, I listed the repeating hash-values in the signature matrix along with their entry means to which row and column they belong to. After that, pair-wise columns in which hash-values are same, I compare the other 3 hash-values for those pair-wise coulumns. If all values are matches, then I return the those column pairs.<br>\n",
        "$\\textbf{Note:}$ Here, I return only the candidate pairs of movie ids. Later, I will return candidate pairs by movie titles.    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T-qjO0PzKZg"
      },
      "source": [
        "## Answer (4): List of candidate pairs by movie IDs<br>\n",
        "After commenting out the \"res1.collect()\", we get the desired output.\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTb6ijpb1j-W"
      },
      "source": [
        "#band1\n",
        "\n",
        "temp01= band1.map(lambda x :(x[1],x[0]))\n",
        "temp101=temp01.groupByKey().map(lambda x : (x[0], list(x[1])))\n",
        "#print(temp101.takeSample(False,2))\n",
        "def ls(x):\n",
        "  f2=[]\n",
        "  for i in range(len(x[1])):\n",
        "    for j in range(i+1,len(x[1])):\n",
        "      f1=[]\n",
        "      if x[1][i][0]== x[1][j][0]:\n",
        "        l1=[]\n",
        "        l1.append(x[1][i][1])\n",
        "        l1.append(x[1][j][1])\n",
        "        f1.append(tuple(l1))\n",
        "        f1.append(x[1][j][0])\n",
        "        #f1.append(x[0])\n",
        "        f2.append(tuple(f1))\n",
        "  return f2\n",
        "filt1=temp101.flatMap(lambda x : [ls(x)])\n",
        "#filt1.take(2)\n",
        "filt1=filt1.flatMap(lambda l: l)\n",
        "#filt1.count()\n",
        "fin1=filt1.groupByKey().map(lambda x : (x[0], list(x[1])))\n",
        "#print(fin1.takeSample(False,2))\n",
        "#fin1.count()\n",
        "def check(x):\n",
        "  if len(x[1])==4:\n",
        "    return x[0]\n",
        "res1=fin1.map(lambda x: check(x))\n",
        "res1=res1.filter(lambda x: x is not None)\n",
        "#res1.collect()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWEhUPqUGAk7"
      },
      "source": [
        "Now, instead of candidate pairs as movie ids, I will return the candidate pairs by movie titles. I used the above code (just copy-pasted) and instead of movie-id, I replaced the movie-titles. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0k9zOgQfzd3R"
      },
      "source": [
        "## Answer (4): List of candidate pairs by movie titles<br>\n",
        "After commenting out the \"res1_modified.collect()\" we get the desired output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTo8ge4-w4xi"
      },
      "source": [
        "keyval_modified=keyval.map(lambda x: (string_to_shingles(x[0],k),x[0])) #it returns the key-value pair where key is \n",
        "#list of 3-shingles for a particular title and corresponding movie id \n",
        "#keyval_modified.takeSample(False,5)\n",
        "key_val_modified=keyval_modified.flatMap(lambda n: [(x, n[1]) for x in n[0]]) # from list of 3-shingles:movie-id, it makes\n",
        "# a pair of a particular shingle and movie id. \n",
        "#key_val_modified.takeSample(False,5)\n",
        "result_modified=key_val_modified.combineByKey(lambda v:[v],lambda x,y:x+[y],lambda x,y:x+y) # it returns a key-value pair \n",
        "# where key is a shingle and and value is the list of movie id associated with a particular shingle.\n",
        "#result_modified.takeSample(False,5)\n",
        "#numOfShingles = result.count() # Calculate, you need to pass this to the update_signature function\n",
        "\n",
        "#signature = # Implement the rest here\n",
        "\n",
        "# You should use map with the update_signature function and a reduce \n",
        "#new_key_val=result.flatMap(lambda n: [(x, n[1]) for x in n[1]])\n",
        "\n",
        "new_key_val_modified=result_modified.map(lambda x: update_signature(x[0],x[1],numOfShingles) )\n",
        "#new_key_val_modified.takeSample(False,2)\n",
        "#signature.take(5)\n",
        "new_key_val_modified = new_key_val_modified.flatMap(lambda list: list)\n",
        "signature_modified = new_key_val_modified.reduceByKey(min)\n",
        "#r=n/b = 20/4 = 5\n",
        "#x = sc.parallelize([1,2,4,5])\n",
        "##max_val = x.reduce(lambda a, b: a if a > b else b)\n",
        "#print(max_val)\n",
        "band1_modified=signature_modified.filter(lambda x : x[0][0] >=0 and x[0][0]<=4)\n",
        "band2_modified=signature_modified.filter(lambda x : x[0][0] >=5 and x[0][0]<=9)\n",
        "band3_modified=signature_modified.filter(lambda x : x[0][0] >=10 and x[0][0]<=14)\n",
        "band4_modified=signature_modified.filter(lambda x : x[0][0] >=15 and x[0][0]<=19)\n",
        "\n",
        "candidate_pairs = []\n",
        "#band1_modified\n",
        "\n",
        "temp01_modified= band1_modified.map(lambda x :(x[1],x[0]))\n",
        "temp101_modified=temp01_modified.groupByKey().map(lambda x : (x[0], list(x[1])))\n",
        "#print(temp101.takeSample(False,2))\n",
        "def ls(x):\n",
        "  f2=[]\n",
        "  for i in range(len(x[1])):\n",
        "    for j in range(i+1,len(x[1])):\n",
        "      f1=[]\n",
        "      if x[1][i][0]== x[1][j][0]:\n",
        "        l1=[]\n",
        "        l1.append(x[1][i][1])\n",
        "        l1.append(x[1][j][1])\n",
        "        f1.append(tuple(l1))\n",
        "        f1.append(x[1][j][0])\n",
        "        #f1.append(x[0])\n",
        "        f2.append(tuple(f1))\n",
        "  return f2\n",
        "filt1_modified=temp101_modified.flatMap(lambda x : [ls(x)])\n",
        "#filt1.take(2)\n",
        "filt1_modified=filt1_modified.flatMap(lambda l: l)\n",
        "#filt1.count()\n",
        "fin1_modified=filt1_modified.groupByKey().map(lambda x : (x[0], list(x[1])))\n",
        "#print(fin1.takeSample(False,2))\n",
        "#fin1.count()\n",
        "def check(x):\n",
        "  if len(x[1])==4:\n",
        "    return x[0]\n",
        "res1_modified=fin1_modified.map(lambda x: check(x))\n",
        "res1_modified=res1_modified.filter(lambda x: x is not None)\n",
        "#res1_modified.collect()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ai99-MbElKGE"
      },
      "source": [
        "The candidate pairs should be of the form\n",
        "\n",
        "<tt>\n",
        "    [(movie1, movie2), (movie1, movie2), ... ]\n",
        "</tt>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brKII7g8RZ8l"
      },
      "source": [
        "### 5. Optional: \n",
        "\n",
        "Optionally, you may also want to compute the pairwise actual Jaccard similarities for each candidate pair and test the number of false positives and negatives for a similarity threshold $s$. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUfs2LhuRi2I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}